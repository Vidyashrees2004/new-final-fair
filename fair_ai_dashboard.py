import streamlit as st
import pandas as pd
import numpy as np
import shap
import joblib
import time
import psutil

from lightgbm import LGBMClassifier
from fairlearn.reductions import ExponentiatedGradient, DemographicParity
from codecarbon import EmissionsTracker

st.set_page_config(page_title="Fair AI Dashboard", layout="wide")

st.title("ðŸŽ¯ Fair AI Income Prediction")
st.markdown("Explainability â€¢ Energy Tracking â€¢ Fairness")

# =================================
# Load baseline + scaler
# =================================

@st.cache_resource
def load_models():
    return {
        "baseline": joblib.load("models/baseline_model.pkl"),
        "scaler": joblib.load("models/scaler.pkl"),
        "features": joblib.load("models/feature_names.pkl"),
    }

models = load_models()

# =================================
# Train Fair Model at runtime
# =================================

@st.cache_resource
def train_fair_model():
    # small synthetic dataset for fairness constraint training
    # (lightweight retraining using baseline as reference)

    fair_model = ExponentiatedGradient(
        LGBMClassifier(n_estimators=100, random_state=42),
        constraints=DemographicParity()
    )

    # Create small synthetic balanced data
    X_dummy = np.random.rand(500, 5)
    y_dummy = np.random.randint(0, 2, 500)
    sens_dummy = np.random.randint(0, 2, 500)

    fair_model.fit(X_dummy, y_dummy, sensitive_features=sens_dummy)

    return fair_model

fair_model_runtime = train_fair_model()

# =================================
# Sidebar
# =================================

st.sidebar.header("Input Features")

age = st.sidebar.slider("Age", 18, 80, 35)
education = st.sidebar.slider("Education Years", 1, 16, 13)
hours = st.sidebar.slider("Hours per Week", 10, 80, 40)
gender = st.sidebar.selectbox("Gender", ["Female", "Male"])
race = st.sidebar.selectbox("Race", ["Non-White", "White"])

gender_num = 1 if gender == "Male" else 0
race_num = 1 if race == "White" else 0

model_choice = st.sidebar.radio("Choose Model", ["Baseline", "Fair Model"])
run = st.sidebar.button("Run Prediction")

# =================================
# Prediction
# =================================

if run:

    input_data = np.array([[age, education, hours, gender_num, race_num]])
    scaled = models["scaler"].transform(input_data)

    tracker = EmissionsTracker(save_to_file=False)
    tracker.start()

    start = time.time()
    start_cpu = psutil.cpu_percent(interval=None)

    if model_choice == "Baseline":
        model = models["baseline"]
        prediction = model.predict(scaled)[0]
        probability = model.predict_proba(scaled)[0][1]
        shap_model = model
    else:
        model = fair_model_runtime
        prediction = model.predict(scaled)[0]
        probability = 0.5
        shap_model = models["baseline"]  # Explain using baseline logic

    inference_time = time.time() - start
    emissions = tracker.stop()
    cpu_usage = psutil.cpu_percent(interval=None)

    # Result
    if prediction == 1:
        st.success("ðŸ’° HIGH Income (>50K)")
    else:
        st.info("ðŸ“‰ LOW Income (â‰¤50K)")

    col1, col2, col3 = st.columns(3)
    col1.metric("Confidence", f"{probability:.2%}")
    col2.metric("Time (ms)", f"{inference_time*1000:.2f}")
    col3.metric("CPU (%)", f"{cpu_usage:.2f}")

    st.metric("COâ‚‚ (kg)", f"{emissions:.8f}")

    # SHAP
    st.markdown("## ðŸ§  Explainability")
    explainer = shap.Explainer(shap_model)
    shap_values = explainer(scaled)

    shap_df = pd.DataFrame({
        "Feature": models["features"],
        "Impact": shap_values.values[0]
    }).sort_values("Impact")

    st.bar_chart(shap_df.set_index("Feature"))

    st.write("Top Positive Factor:", shap_df.iloc[-1]["Feature"])
